# ü¶ôüå≤ü§è Alpaca-LoRA && Starwhale

This repo is forked from [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora), see the [original README.md](README_original.md). We add some Starwhale support for this repo, users could manage lifecycle of the model by starwhale, including:
- finetune a new version of model locally or remotelly and get a finetuned version of model
- serve an API locally or remotelly
- evaluate the model with Starwhale datasets

## Build Starwhale Datasets

```python
python build_swds.py
```

## Build Starwhale Model

```python
python build_swmp.py
```

## Finetune the model with dataset and gain a new verson

```bash
swcli model run -u llama-7b-hf/version/lateset -d alpaca_data/version/lateset -h finetune
```

## Serve an API for the finetuned version of model

```bash
swcli model serve llama-7b-hf/version/lateset
```